{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kh7ikCw1dWx5"
   },
   "source": [
    "# GRO620 - Activité procédurale 1\n",
    "\n",
    "Dans cette activité, nous allons principalement travailler sur les éléments nécessaires pour capter une image numériquement, les transformations entre repères 2D et 3D, et l'encodage numérique de la couleur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45339,
     "status": "ok",
     "timestamp": 1622381462155,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "pC6BnG_3dWyA",
    "outputId": "4486fcd9-17b2-4018-e963-c0b64774adcc"
   },
   "outputs": [],
   "source": [
    "# Préambule\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Si vous utilisez Google Colab, vous devez d'abord monter votre Google Drive\n",
    "## où se trouve vos données. \n",
    "## Commentez les trois lignes suivantes en ajustant le chemin vers votre propre\n",
    "## dossier :\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# %cd /content/gdrive/MyDrive/gro620-e21\n",
    "\n",
    "## Pour retrouver le chemin depuis Jupyter, vous pouvez utiliser ceci :\n",
    "# !ls /content/gdrive/MyDrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1xSdXoMdWyB"
   },
   "source": [
    "## Acquisition et caractéristiques de la lumière\n",
    "\n",
    "### Q1.1\n",
    "\n",
    "À partir de la figure 2.23 du livre de référence, décrivez en une phrase le rôle de chacune des étapes de la chaîne d'acquisition d'images numériques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPRDNqrrdWyB"
   },
   "source": [
    "Optics : Redirection de la lumière pour que l'image soit dans le bon sens et de la bonne grandeur.\n",
    "Réponse : Apporter la lumière au capteur.\n",
    "\n",
    "Aperture : Gestion de la grandeur du trou qui laisse passer la lumière, de la quanité et de l'intensité de la lumière qui se rend aux capteurs\n",
    "Réponse : Meilleure profondeur de champs, pour flouter ce qu'on désir\n",
    "\n",
    "Shutter : Gestion du temps d'exposition du capteur à la lumière pour modifier le depth of field ou le motion blur dans le cas d'image dynamique\n",
    "Réponse : si c'est sombre, on peut s'exposer plus longtemps pour augmenter la luminosité, peut augmenter le motion blur\n",
    "\n",
    "Sensor : Récolte des photons et accumulation de ceux-ci\n",
    "Réponse : Transformation des photons en signaux électrique\n",
    "\n",
    "Gain : Amplification des signaux électrique provoqué par les photon\n",
    "Réponse : Peut faire en sorte d'amplifier le bruit\n",
    "\n",
    "ADC : Conversion des signaux analogique en signaux numérique\n",
    "\n",
    "Mosaic : C'est le passage d'un \"color filter array\" aux valeurs RGB\n",
    "Réponse : Le CFA c'est des pattern comme le Bayer pattern, on cherche à faire la moyenne des couleurs autour de celle percu pour donner une valeur au au couleur qui ne sont pas mesuré\n",
    "\n",
    "Denoise and sharpen : On enlève le bruit dans l'image (Avec du digital signal processing)\n",
    "Réponse : On enlève le bruit et défini mieux les contours des informations provenant de la dernière étape\n",
    "\n",
    "White balance : Approché les point blanc de l'iamge d'un blanc pure pour compenser les grande illuminations colorées\n",
    "Réponse :\n",
    "\n",
    "Gamma : mapping of the luminance values through a gamma function to increase the perceived dynamic range of the signal.\n",
    "Réponse :On compense avec la fonction comment les yeux voient vraiment les choses, ce qu'on peut percevoir va apparaître plus \n",
    "\n",
    "Compress : réduction de la taille du fichier pour que ce soit utilisable.\n",
    "Réponse : Il peut y avoir des pertes de résolution de la couleur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zdxhihn2dWyB"
   },
   "source": [
    "### Q1.2\n",
    "\n",
    "Quelle est la différence entre paramètres intrinsèques et extrinsèques du caméra ? Décrivez chaque type en une phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiFuS6rPdWyC"
   },
   "source": [
    "Paramètre propres à la caméra : point focal, aperture max, etc. = Intrinséque\n",
    "Paramètre provenant de l'environnement : Illumination, mouvement,ou est la caméra etc. = extrinsèque, \n",
    " Différence : L'un représente les paramètre propre à la caméra et qui ne change pas tandis que l'autre représente des paramètres propres à l'environnement, qui eux peuvent changer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FWZECptdWyC"
   },
   "source": [
    "### Q1.3\n",
    "\n",
    "Soit la configuration intrinsèque d'une caméra représentée par la matrice $K$ :\n",
    "\n",
    "$$\n",
    "K = \\begin{bmatrix} \n",
    " 620 &   0 & 1024 \\\\ \n",
    "   0 & 620 &  512 \\\\ \n",
    "   0 &   0 &    1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Le capteur de cette caméra a une taille de 30 mm x 15 mm.\n",
    "\n",
    "Pouvez-vous estimer la distance focale en mm de la lentille de cette caméra à partir de la matrice $K$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "mcfUfXCCdWyC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.08203125\n"
     ]
    }
   ],
   "source": [
    "# Réponse ici.\n",
    "import numpy as np\n",
    "w = 30\n",
    "K = np.array([[620.,   0., 1024.],\n",
    "              [  0., 620.,  512.],\n",
    "              [  0.,   0.,    1.]\n",
    "])\n",
    "\n",
    "f = K[0,0]*(30/(1024*2))\n",
    "print(f)\n",
    "\n",
    "#La matrice K est en pixel, on veut savoir le rapport mm/pixel et on\n",
    "# on multiplie avec la distance focal en mm\n",
    "#1024 est choisi pour C_x car cela représente le centre de la caméra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quJcFsPbdWyD"
   },
   "source": [
    "### Q1.4\n",
    "\n",
    "Dans le cadre de cet APP, nous considérons les caméras comme étant idéales, c'est-à-dire qu'on peut obtenir leurs caractéristiques intrinsèques et extrinsèques à partir de quelques paramètres seulement.\n",
    "\n",
    "**a)** Qu'est-ce qui rend les vraies caméras non-idéales ? Nommez des facteurs autant pour les caractéristiques intrinsèques que extrinsèques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Erl2fPTidWyD"
   },
   "source": [
    "Leur capacité d'ajustements à la quantité de lumière reçue n'est pas parfaites, du bruit ainsi que des aberration dû à l'imperfection des lentilles sphérique (intrinsèque). \n",
    "\n",
    "Les surfaces ayant une réflexion diffuse ne sont pas bien capter par l'\"Apperture\" et l'illumination de l'environnement trop grand ou trop petit peut provoquer des problème et aussi le postionnement de la caméra (extrinsèque)\n",
    "Réponse : Réalité des imperfections provenant de la fabrication de la caméra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sfg46RtdWyD"
   },
   "source": [
    "**b)** Que doit on faire pour obtenir les caractéristiques d'une caméra non-idéale ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bezo06eCdWyE"
   },
   "source": [
    "En faisant une estimation basé sur plusieurs mesure. On pourrait aussi introduire un pourcentage d'erreur. \n",
    "Réponse : Faire une calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhFn190TftCu"
   },
   "source": [
    "### Q1.5\n",
    "\n",
    "Dans cette image synthétique : \n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/c/cd/Specular_highlight.jpg)\n",
    "\n",
    "(source: [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Specular_highlight.jpg))\n",
    "\n",
    "**a)** Quelle(s) partie(s) correspondent à l'illumination diffuse et les reflets spéculaires ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yFIYACqdXa3"
   },
   "source": [
    "Les partie où il y a un passage d'une zone illuminée à plus sombre = illumination diffuse\n",
    "Réponse : Tout ce qui fait qu'il y a de la couleur\n",
    "\n",
    "Les partie où il y a des points blancs = reflet spéculaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXkcFjFKdXa4"
   },
   "source": [
    "**b)** Quelle information est nécessaire pour déterminer les caractéristiques et emplacements exacts des sources de lumières dans cette image ? Vous pouvez répondre en utilisant des éléments de la *Bidirectional Reflectance Distribution Function* (BRDF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGntKizNdXa5",
    "tags": []
   },
   "source": [
    "Nous avons besoin de l'angle d'incidence et de réflexion, la longeur d'onde et les angles de rotation par rapport à la normale de la surface pour le rayon incident et réfléchis.\n",
    "Réponse : C'est très difficile à faire seulement à partir de la photo, on pourrait le faire si on avait beaucoup de points de vue différent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhFn190TftCu"
   },
   "source": [
    "### Q1.6\n",
    "\n",
    "**a)** Pourquoi deux appareils de capture peuvent produire des valeurs RGB différentes d'une même couleur ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4LmStT2f6C1"
   },
   "source": [
    "Car rien n'empêche les fabricant de caméra de changer un peu les valeurs par la suite pour que l'image correspondent mieux à leur besoin.\n",
    "Réponse : Les caméras ne sont pas tous calibré de la même façon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obSsXTc8f5XM"
   },
   "source": [
    "**b)** Que peut-on faire pour comparer numériquement des couleurs provenant de deux capteurs différents ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ629ialf4VV"
   },
   "source": [
    "Il faudrait savoir les informations qui apportent un changement au calcul de la matrice RGB, et faire l'équation 2.104 pour avoir la matrice XYZ. Il sera possible de comparer ces deux matrice pour comparer des bananes avec des bananes.\n",
    "Réponse : on a besoin de la matrice de conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKQOpwTVdWyE"
   },
   "source": [
    "## Repères et coordonnées\n",
    "\n",
    "### Q2.1\n",
    "\n",
    "Supposons ces 2 repères :\n",
    "\n",
    "![](images_doc/proc1-q2_1-frames.png)\n",
    "\n",
    "**a)** Trouvez la matrice homogène permettant de transformer un point du repère $\\{1\\}$ au repère $\\{0\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "jULxdVBsdWyE",
    "outputId": "630316fc-4340-46fa-aa1f-54f653075553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_mat:\n",
      " [[ 0.    1.    0.    0.24]\n",
      " [ 1.    0.    0.    0.08]\n",
      " [ 0.    0.   -1.    0.12]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "T_10:\n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "T_10 = np.identity(4) # Génère une matrice identité 4x4\n",
    "t_mat = np.array([-240,-80,120])\n",
    "t_mat_t = t_mat.transpose()\n",
    "\n",
    "T_mat = np.array([[0,1,0,0],[1,0,0,0],[0,0,-1,0],[0.24,0.08,0.12,1]])\n",
    "#On vérifie quel axes sont alligné avec lesquelles, et on met les signes en conséquence\n",
    "# On pars du repère 0 et on regarder les dimensions, on doit garder des unité\n",
    "T_mat = T_mat.transpose()\n",
    "\n",
    "print(\"T_mat:\\n\", T_mat)\n",
    "print(\"T_10:\\n\", T_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJIOwDUPdWyF"
   },
   "source": [
    "**b)** Trouvez maintenant la transformation inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "LH35FSWqdWyG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    1.    0.   -0.08]\n",
      " [ 1.    0.    0.   -0.24]\n",
      " [-0.   -0.   -1.    0.12]\n",
      " [ 0.    0.    0.    1.  ]]\n"
     ]
    }
   ],
   "source": [
    "T_01 = np.identity(4)\n",
    "T_mat_t = np.linalg.inv(T_mat)\n",
    "print(T_mat_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2ximr9WdWyG"
   },
   "source": [
    "**c)** Soit le point $p_0 = [8, 5, 1]^T$, un point dans le repère $\\{0\\}$. Trouvez $p_1$, ses coordonnées dans le repère $\\{1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b22z2cUnf0WF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "nj0k5hkLdWyG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.92  7.76 -0.88  1.  ]\n"
     ]
    }
   ],
   "source": [
    "p_0 = [8, 5, 1, 1]\n",
    "p_1 = T_mat_t @ p_0\n",
    "print(p_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPkWLvBydWyH"
   },
   "source": [
    "### Q2.2\n",
    "\n",
    "Supposons maintenant que le repère $\\{1\\}$ représente une caméra avec les caractéristiques intrinsèques $K$ de la question Q1.3.\n",
    "\n",
    "**a)** Trouvez la matrice de projection P complète permettant de projeter un point $p$ décrit dans le repère $\\{0\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "6XhSj3FRdWyH",
    "outputId": "ab32f10e-8b2c-4cea-ed94-5ec725bbe94c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K1:\n",
      " [[6.200e+02 0.000e+00 1.024e+03 0.000e+00]\n",
      " [0.000e+00 6.200e+02 5.120e+02 0.000e+00]\n",
      " [0.000e+00 0.000e+00 1.000e+00 0.000e+00]\n",
      " [0.000e+00 0.000e+00 0.000e+00 1.000e+00]]\n",
      "P1:\n",
      " [[ 0.000e+00  6.200e+02 -1.024e+03  7.328e+01]\n",
      " [ 6.200e+02  0.000e+00 -5.120e+02 -8.736e+01]\n",
      " [ 0.000e+00  0.000e+00 -1.000e+00  1.200e-01]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  1.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# print(K) # Si vous n'avez pas réutilisé la variable K, elle aura toujours la même valeur qu'à la question Q1.3.\n",
    "K1 = np.zeros((4,4))\n",
    "\n",
    "K1[0:3,0:3] = K\n",
    "K1[3,3] = 1\n",
    "print(\"K1:\\n\", K1)\n",
    "\n",
    "#pourquoi est-ce qu'on doit prendre la matrice T inverse?\n",
    "P1 = K1 @ T_mat_t\n",
    "print(\"P1:\\n\", P1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UEWupgIdWyI"
   },
   "source": [
    "**b)** Soit le point $p_0 = [0.250, 0.010, 0.000]$. Trouvez le point $x_s$, les coordonnées du point $p_0$ perçu par la caméra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "WryXyIycdWyI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[662.33333333 563.66666667   1.           8.33333333]\n"
     ]
    }
   ],
   "source": [
    "p_0 = np.array([0.250, 0.010, 0.000])\n",
    "\n",
    "#C'est quoi que ca veut dire d'augmenter une matrice?\n",
    "p_w = np.array([0.250, 0.010, 0.000,1])\n",
    "\n",
    "x_s_p = P1@p_w\n",
    "# print(x_s_p)\n",
    "\n",
    "x_s = x_s_p/x_s_p[2]\n",
    "print(x_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpa--SomdWyY"
   },
   "source": [
    "## Reprojection 2D à 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVHRnJsIdWyY"
   },
   "source": [
    "### Q3.1\n",
    "\n",
    "Supposons que le plan XY du repère $\\{0\\}$ est un convoyeur. Quelle serait sa largeur maximale (mesurée sur l'axe Y) si on souhaite que la caméra la capte au complet dans son image ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2WqHjEONdWyZ"
   },
   "outputs": [],
   "source": [
    "l_conv = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jk6xchjCdWyZ"
   },
   "source": [
    "### Q3.2\n",
    "\n",
    "Soit le point $x_s = [120, 200]$, un point dans l'image perçu par la caméra décrite plus haut. On suppose que le point perçu se trouve sur le plan XY du repère $\\{0\\}$. Trouvez les coordonnées du point $p_0$ qui correspond à ce même point dans le repère $\\{0\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "GYiNDm-BdWya"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79.48 67.64  0.12  1.  ]\n"
     ]
    }
   ],
   "source": [
    "x_s_2 = np.array([120,200])\n",
    "P1_inv = np.linalg.inv(P1)\n",
    "x_rp = x_s/x_s[3]\n",
    "print(x_rp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "proc_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
